<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice-Controlled AI Assistant</title>
    <style>
        body {
            font-family: 'Arial', sans-serif;
            color: white;
            margin: 0;
            padding: 0;
            overflow: hidden;
        }

        h1 {
            font-size: 36px;
            margin-bottom: 20px;
        }

        button {
            background-color: #09f;
            color: white;
            padding: 15px 30px;
            border: none;
            font-size: 20px;
            cursor: pointer;
            border-radius: 8px;
            transition: background-color 0.3s;
        }

        button:hover {
            background-color: #06c;
        }

        #output {
            margin-top: 30px;
            font-size: 24px;
            font-weight: bold;
            color: white;
        }

        .container {
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            position: relative;
        }

        .content-wrapper {
            z-index: 2;
            text-align: center;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="content-wrapper">
            <h1>Voice-Controlled AI Assistant</h1>
            <button onclick="startListening()">Start Listening</button>
            <p id="output">Your voice command will appear here...</p>
        </div>
    </div>

    <script>
        const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
        recognition.continuous = false;  // Only listen once per click
        recognition.interimResults = false;  // Only get final results (no partials)

        // Listen for results from speech recognition
        recognition.onresult = function(event) {
            let transcript = event.results[event.results.length - 1][0].transcript.toLowerCase();

            // Debugging output
            console.log("Heard: " + transcript);

            processCommand(transcript);
        };

        // Handle errors
        recognition.onerror = function(event) {
            console.error("Error occurred in speech recognition: ", event.error);
        };

        // Start listening for commands
        function startListening() {
            recognition.start();
            document.getElementById("output").textContent = "AI is listening for a command...";
        }

        // Process commands after recognition
        function processCommand(command) {
            const lowerCaseCommand = command.toLowerCase();

            if (lowerCaseCommand.includes("open youtube")) {
                openWebsite("https://www.youtube.com");
            } else if (lowerCaseCommand.includes("open instagram")) {
                openWebsite("https://www.instagram.com");
            } else if (lowerCaseCommand.includes("search")) {
                const query = command.replace("search", "").trim();
                searchGoogle(query);
            } else if (lowerCaseCommand.includes("stop listening")) {
                stopListening();
            } else {
                document.getElementById("output").textContent = "I didn't understand that command.";
            }
        }

        // Open a website in a new tab
        function openWebsite(url) {
            window.open(url, "_blank");
        }

        // Perform a Google search
        function searchGoogle(query) {
            const googleSearchUrl = `https://www.google.com/search?q=${encodeURIComponent(query)}`;
            window.open(googleSearchUrl, "_blank");
        }

        // Stop listening
        function stopListening() {
            recognition.stop();
            document.getElementById("output").textContent = "AI is now inactive.";
        }
    </script>
</body>
</html>
